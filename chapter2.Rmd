---
output:
  html_document: default
---
# 2. Regression and Model Validation {.tabset .tabset-fade .tabset-pills}

## Data Wrangling

First, I started with data wrangling exercise. I read the data from [http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt](http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt). 


```{r echo = T, message = F, warning = F}
library(Matrix)
library(ggplot2)
library(dplyr)

setwd("/Users/veikko/Desktop/datakurssi/IODS-project/data")
lrn14 <- read.table("JYTOPKYS3-data.txt", header = T, sep = "\t")
str(lrn14)
dim(lrn14)
```


Then I modified the dataset. I followed the instructions and created attitude, deep, stra and surf variables by combining questions in the learning2014 data. 


```{r echo = T}
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")

# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)

# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)

# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)

```


Then I scaled all combination variables to the original scale and finally, excluded observations where the exam points variable is zero. My final list of variables was then: gender, age, attitude, deep, stra, surf and points.


```{r echo = T}
colnames(lrn14)[57] <- "age"
colnames(lrn14)[58] <- "attitude"
colnames(lrn14)[59] <- "points"

varsToGet <- c("gender", "age", "attitude", "deep", "stra", "surf", "points")
new_lrn14 <- select(lrn14, one_of(varsToGet))

new_lrn14 <- filter(new_lrn14, points > 0)

```


After this, I changed my working directory to the IODS project folder and saved the analysis dataset to the folder as a csv-file. 


```{r echo = T, message = F, warning = F}
setwd("/Users/veikko/Desktop/datakurssi/IODS-project")
getwd()

write.csv(new_lrn14, file = "learning2014.csv", sep = ",")
```


Then I wanted to check that everything went as planned, so I read the just created csv-file. 


```{r echo = T}
learning2014 <- read.csv("learning2014.csv", sep = ",", header = T)
learning2014 <- learning2014[-1]

str(learning2014)
head(learning2014)

#Almost forgot to scale the attitude variable
learning2014$attitude <- learning2014$attitude / 10
head(learning2014)
str(learning2014)
summary(learning2014)

```

## Analysis


Just to briefly repeat, the dataset consists of seven variables: gender, age, attitude, deep, stra, surf and points. In this analysis points is the dependent variable.

* age: Age (in years) derived from the date of birth
* gender: Gender of the respondent M (Male), F (Female)
* points: Exam points
* attitude: Global attitude toward statistics
* deep: average of deep learning questions
* stra: average of strategic learning questions
* surf: average of concentration capabilities questions

I have already, in previous section, provided a summary of the variables, which shows numerically min, max, mean, median and quantile infromation regarding each variable. Next, I will show three graphical illustrations about the data. First, I will show an overview of the data with a ggpairs function observations grouped by gender. Then I'll make a histogram of the points variable. Finally, I am going to group the data by exam performance into three groups (as close to equal size as possible) and provide a ggpairs illustration with that grouping.

```{r echo = T, warning = F, message= F, fig.height=7, fig.width=10}
library(GGally)

#first ggpairs 
ggpairs(learning2014, mapping = aes(col = gender, alpha = 0.3), 
             lower = list(combo = wrap("facethist", bins = 20)))
```

```{r echo = T, warning = F}
#drawing a histogram of points
tbl <- table(learning2014$points) 
f <-  factor(learning2014$points, levels = 7:33)
barplot(table(f), xlab = "Points", ylab = "Count")
```

```{r echo = T, warning = F, fig.height=7, fig.width=10}
#splitting the data into 3 groups based on points variable
learning2014$pgroup <- as.numeric(cut_number(learning2014$points,3))
learning2014$pgroup2 <- factor(learning2014$pgroup, labels = c("low", "middle", "high"))
table(learning2014$pgroup2)

#drawing a second ggpairs 
test.learn <- subset(learning2014, select = c("age","attitude", "deep", "stra", "surf", "points", "pgroup2"))
ggpairs(test.learn, mapping = aes(col = pgroup2, alpha = 0.3), 
        lower = list(combo = wrap("facethist", bins = 20)))
```

  
We can see many interesting things from the plots previously drawn. First of all, there is a gender based difference: men are doing better in terms of exam points than women, but this would require statistical test in order to determine whether the difference is statistically signifficant or not. From the first ggpairs matrix, one can also see the correlation coefficients and that attitude has the highest correlation with points. High attitude correlates with high exam points. Similarly, stra variable has a positive correlation with points. Surf, deep and age on the other hand, seem to be negatively correlated with points. Correlation coefficients are different for men and women, but those differences do not seem to be that high, if we just look at points vs. other variables (correlation coefficients are within 0.1 range between genders in case of same variables).

From the two other plots we can see how the points are distributed. As an extra I grouped the data by dividing points results into three categories "low", "middle" and "high". In the second ggpairs matrix one can see that there is much more variation between correlation coefficients of different groups than in comparison to grouping by gender. 


I chose not to follow the homework instruction so strictly at this point, because the idea of manually iterating through the model selection seems pointless. One should also remember that it matters in which order one includes the variables into the model, so one should not pointlessly start experimenting with different variables. Our data is luckily low in dimensions, so using the best subset selection is a possibility. I reckoned that I would let the best subset selection do the variable selection for me; to present me with the best model with three variables (as requested in the exercise instructions). Here is how I did it:


```{r echo = T, fig.height=4, fig.width=6}
library(leaps)

#let's remove those two additional variables
drops <- c("pgroup", "pgroup2")
learning2014_org <- learning2014[ , !(names(learning2014) %in% drops)]

#model validation by best subset selection
regfit.full <- regsubsets(points~.,learning2014_org)
reg.summary <- summary(regfit.full)

#some validation metrics
which.max(reg.summary$adjr2)
which.min(reg.summary$cp )
which.min(reg.summary$bic )

#let's try to do just one plot
par(mfrow = c(1,1))

plot(reg.summary$cp ,xlab="Number of Variables ",ylab="Cp", type="l")
points(3,reg.summary$cp[3],col="red",cex=2,pch=20)

#here we select the best model with 3 variables
coef(regfit.full ,3)
```


Apparrently, choosing three variables is not such a bad idea, as Cp validation metric recommends three variables to be in the ideal model. Most importantly, now we know the variables for the best three variable model: attitude, stra and age. Next we do the model fitting with those variables.


```{r echo = T, fig.height=6, fig.width=9}
lm.fit <- lm(points ~ attitude + stra + age, data=learning2014_org)
summary(lm.fit)

par(mfrow = c(2,2))
plot(lm.fit, which = c(1,2,5))

```


In the output we can see the model fit and some important information regarding the model. attitude seems to be the only statistically signifficant variable, the others have a p-value higher than 0.5. Age has a mild negative coefficient and affects negatively to the points variable. Gaining one point higher stra value increases points by one and attitude by almost 3.5. R^2 is 0.2182 and Adjusted R^2 is 0.2037, which mean that the model explains 1/5 of the variance of the dependent variable. Adjusted R^2 is a measure for comparing different models as R^2 increases naturally by including more variables, as this is not the case with Adjusted R^2. F-statistic tells us that coefficients are not zero. 

We can observe from the regression diagnostic plots that there are no huge problems with the residuals (no signs of heteroscedasticity) and there does not seem to be individual points with model manipulative amounts of leverage.
